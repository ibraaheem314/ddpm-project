training:
  batch_size: 8
  learning_rate: 2e-4
  epochs: 100
  gradient_accumulation: 4

diffusion:
  timesteps: 1000
  beta_schedule: cosine

model:
  in_channels: 3
  out_channels: 3
  image_size: 32
  channels: 128
  channels_mult: [1, 2, 2, 2]
  num_res_blocks: 2
  num_heads: 2

advanced:
  dropout: 0.1
  ema_decay: 0.999
  save_interval: 1000